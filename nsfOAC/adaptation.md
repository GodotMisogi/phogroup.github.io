---
layout: page
title: Neural Architecture Adaptation Problem
permalink: /nsfOAC/adaptation/
---
### Problem description
It has been observed that deep neural networks (DNN) create increasingly
simpler but more useful  representations  of the learning problem layer by layer. Furthermore, empirical
evidence supports the paradigm that depth of a network is of crucial
importance. Such large networks, however, yield
computationally complex optimization problems. Furthermore, despite
such successes, the mechanisms behind deep learning remain a mystery
and a trial-and-error approach (Architecture search) is often employed to retrieve the best
neural network. Thus, there is a need for
adaptive principles to guide the architecture design of a neural network. In this project we focus on developing mathematically principled schemes for progressively adapting neural network to generalize well on the given data set and possibly outperform an adhoc baseline neural network.

### Adopted strategy

Based on two different design philosophies, we have developed two different algorithms:

####  A two-stage strategy for deep neural network architecture adaptation




#### Network topological derivative approach for deep neural architecture adaptation.


